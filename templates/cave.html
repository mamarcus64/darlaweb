<div class="center-col">

<h3><a href="uploadsound">Click here to run completely automated vowel
  extraction</a> on your untranscribed audio files.</h3>

  <p>The tool provides the facility
  to edit the transcripts produced by the speech recognizer and
  rerun the analysis.</p>

  <p> It is recommended that you look through the discussion below on the system's functionality and limitations before you begin. </p>

<a name="why"></a><h2>Why completely automate vowel extraction?</h2>
<p>In the last few years, sociolinguists have begun using semi-automated speech processing methods such as Penn's <a href="http://fave.ling.upenn.edu/index.html">FAVE</a> program to extract vowel formants. These systems have accelerated the pace of linguistic research, but require significant human effort to manually create sentence-level transcriptions. </p>

<p>We believe that sociolinguistics is on the brink of an even more
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. This technology
  would make it possible to quickly extract pronunciation features
  from hours of recordings, including YouTube and vast audio
  archives. DARLA takes a step in this direction. </p>

  <a name="how"></a><h2>How does it work?</h2>

<p>While ASR is far from perfect, we believe sociophoneticians do not need to wait for years to take advantage of speech recognition. Unlike applications like dictation software where accurate word recognition is the primary goal, sociophonetics typically focuses on a much narrower objective: extracting a representative vowel space for speakers, based on stressed vowel tokens.
For example, it would usually not be crucial to know that the stressed vowel in the word "turning" was extracted from "turn it" rather than "turning", or that "tack" was wrongly transcribed as "sack".  Such differences will have little effect on the speaker's vowel space for many sociophonetic questions. </p>

<p>It turns out that most ASR errors affect the identity of the <i>words</i> but not the identity of the <i>vowels</i> (especially stressed vowels), making it an ideal technology for automated vowel analysis. 
Of course, there will be instances of vowel error, but the effect of these errors is reduced by the large amount of data with hundreds or thousands of vowel tokens.</p>

<p>Important contrasts like "cot" versus "caught" tend to be handled by ASR's modeling of grammatical plausibility (using a <a href="http://en.wikipedia.org/wiki/Language_model" target="_blank">language model</a>). The system would be unlikely to transcribe "I caught the ball" as "I cot the ball" since the latter would be improbable under an English language model.</p>

<p>Finally, since DARLA shows probabilities for the phonetic environment around each vowel (e.g., obstruent+vowel+nasal consonant), researchers can examine contrasts like pin/pen versus pit/pet.</p>

<p>See our <a href="http://cs.wellesley.edu/~sravana/papers/darla_naacl.pdf" target="_blank">NAACL paper</a> for more information.</p>

<a name="limits"></a><h2>Limitations</h2>

<p> This system cannot provide perfect transcriptions or perfect formant measurements. The automatic transcriptions typically contain a very large number of errors, especially in free speech data. Current ASR technology simply cannot match the accuracy of human manual transcriptions.</p>

<p>DARLA's automated approach to sociophonetics may help open the way
toward large-scale audio analysis, but there is a tradeoff. As with
many other sciences, automated processing necessitates error-reporting
in the measurements, not just in the statistical modeling. We find
that the system can be useful for extracting a representative vowel space for sociophonetic purposes, as long as error levels are considered and reported. In other words, fast large-scale data analysis requires a higher tolerance of noise in the data.</p>

</div>
